{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.fft\n",
    "from scipy.interpolate import interp1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "def capture_audio(duration=5, rate=44100, channels=1, chunk=1024):\n",
    "    \"\"\"\n",
    "    Captures audio from the microphone for a given duration.\n",
    "\n",
    "    :param duration: Duration to record in seconds\n",
    "    :param rate: Sampling rate\n",
    "    :param channels: Number of audio channels\n",
    "    :param chunk: Number of frames per buffer\n",
    "    :return: Captured audio data as a numpy array\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paFloat32, channels=channels, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Capturing audio. Please speak into the microphone.\")\n",
    "    frames = []\n",
    "    for _ in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(np.frombuffer(data, dtype=np.float32))\n",
    "\n",
    "    print(\"Audio capture finished.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    return np.concatenate(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def pitch_scale(audio, sr, n_steps):\n",
    "    \"\"\"\n",
    "    audio: numpy array representing the audio signal\n",
    "    sr: int, the sampling rate of the audio\n",
    "    n_steps: int, number of semitones to shift the pitch. Range [-11, 11]\n",
    "    \"\"\"\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def apply_warping_function(frames, warp_function, alpha):\n",
    "    ### Usage\n",
    "    # To use these functions, you'll need to provide:\n",
    "    # - `frames`: A list (or array) of frame data. Each frame should be a NumPy array representing the audio signal.\n",
    "    # - `warp_function`: A string specifying the warping function to use ('asymmetric', 'symmetric', 'power', 'quadratic', or 'bilinear').\n",
    "    # - `alpha`: The parameter for the warping function.\n",
    "    warped_freqs = []\n",
    "    for frame in frames:\n",
    "        m = len(frame)\n",
    "        omega = np.arange(1, m + 1) / m * np.pi\n",
    "        omega_warped = np.copy(omega)\n",
    "\n",
    "        if warp_function in ['asymmetric', 'symmetric']:\n",
    "            omega0 = 7/8 * np.pi\n",
    "            if warp_function == 'symmetric' and alpha > 1:\n",
    "                omega0 = 7 / (8 * alpha) * np.pi\n",
    "            \n",
    "            mask = omega <= omega0\n",
    "            omega_warped[mask] = alpha * omega[mask]\n",
    "            omega_warped[~mask] = alpha * omega0 + ((np.pi - alpha * omega0) / (np.pi - omega0)) * (omega[~mask] - omega0)\n",
    "\n",
    "            omega_warped[omega_warped >= np.pi] = np.pi - 0.00001 + 0.00001 * omega_warped[omega_warped >= np.pi]\n",
    "\n",
    "        elif warp_function == 'power':\n",
    "            omega_warped = np.pi * (omega / np.pi) ** alpha\n",
    "\n",
    "        elif warp_function == 'quadratic':\n",
    "            omega_warped = omega + alpha * (omega / np.pi - (omega / np.pi) ** 2)\n",
    "\n",
    "        elif warp_function == 'bilinear':\n",
    "            z = np.exp(omega * 1j)\n",
    "            omega_warped = np.abs(-1j * np.log((z - alpha) / (1 - alpha * z)))\n",
    "\n",
    "        omega_warped_scaled = omega_warped / np.pi * m\n",
    "        interp_func = interp1d(np.arange(1, m + 1), frame, kind='linear', fill_value='extrapolate')\n",
    "        warped_frame = interp_func(omega_warped_scaled)\n",
    "\n",
    "        if np.isreal(frame[-1]):\n",
    "            warped_frame[-1] = np.real(warped_frame[-1])\n",
    "\n",
    "        warped_frame[np.isnan(warped_frame)] = 0\n",
    "        warped_freqs.append(warped_frame)\n",
    "\n",
    "    return warped_freqs\n",
    "\n",
    "def piecewise_linear_transformation(frame, alpha, breakpoint=0.5):\n",
    "\n",
    "    \"\"\"\n",
    "    Apply a piecewise-linear transformation to an audio frame.\n",
    "    :param frame: Numpy array representing the audio frame.\n",
    "    :param alpha: Scaling factor for the transformation.\n",
    "    :param breakpoint: Point in the normalized frequency range [0, 1] where the\n",
    "                    piecewise transformation changes.\n",
    "    \"\"\"\n",
    "    m = len(frame)\n",
    "    omega = np.linspace(0, 1, m)  # Normalized frequency range from 0 to 1\n",
    "\n",
    "    # Piecewise-linear transformation\n",
    "    # For frequencies below the breakpoint, scale by alpha\n",
    "    # For frequencies above the breakpoint, scale by 1.5\n",
    "    omega_warped = np.where(omega < breakpoint, omega * alpha, omega * 1.5)\n",
    "\n",
    "    # Ensure omega_warped stays within [0, 1]\n",
    "    omega_warped = np.clip(omega_warped, 0, 1)\n",
    "\n",
    "    # Apply transformation to the frequency domain\n",
    "    interp_func = interp1d(omega, frame, kind='linear', fill_value=\"extrapolate\")\n",
    "    warped_frame = interp_func(omega_warped)\n",
    "\n",
    "    return warped_frame\n",
    "\n",
    "def process_audio_data(audio_data, sampling_rate, pitch_shift_steps, warping_type, warping_param):\n",
    "    # Apply pitch scaling\n",
    "    transformed_audio = pitch_scale(audio_data, sampling_rate, pitch_shift_steps)\n",
    "    # Apply frequency warping\n",
    "    if warping_type in ['bilinear', 'quadratic', 'power', 'piecewise-linear']:\n",
    "        frames = np.array_split(transformed_audio, len(transformed_audio) // 1024)  # Splitting into frames\n",
    "        warped_frames = apply_warping_function(frames, warping_type, warping_param)\n",
    "        transformed_audio = np.concatenate(warped_frames)  # Concatenating the frames back\n",
    "\n",
    "    return transformed_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "def save_transformed_audio(transformed_audio, filename=\"output.wav\"):\n",
    "    sf.write(filename, transformed_audio, 44100, format='WAV', subtype='PCM_24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing audio. Please speak into the microphone.\n",
      "Audio capture finished.\n",
      "audio_data is correctly formatted.\n",
      "sampling_rate is correctly formatted.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Capture audio\n",
    "    audio_data = capture_audio(duration=5)  # 5 seconds of audio\n",
    "    sampling_rate = 44100  # Same as in capture_audio\n",
    "    # Check if audio_data is a one-dimensional numpy array\n",
    "    if isinstance(audio_data, np.ndarray) and audio_data.ndim == 1:\n",
    "        print(\"audio_data is correctly formatted.\")\n",
    "    else:\n",
    "        print(\"audio_data is not correctly formatted. It should be a one-dimensional numpy array.\")\n",
    "\n",
    "    # Check if sampling_rate is an integer\n",
    "    if isinstance(sampling_rate, int):\n",
    "        print(\"sampling_rate is correctly formatted.\")\n",
    "    else:\n",
    "        print(\"sampling_rate is not correctly formatted. It should be an integer.\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Save original audio\n",
    "    sf.write(\"original_audio.wav\", audio_data, sampling_rate, format='WAV', subtype='PCM_24')\n",
    "\n",
    "    # Apply transformations\n",
    "    pitch_scaled_audio = pitch_scale(audio_data, sampling_rate, n_steps=4)  # Example pitch scaling\n",
    "    bilinear_warped_audio = apply_warping_function([pitch_scaled_audio], 'bilinear', 0.2)[0]\n",
    "    quadratic_warped_audio = apply_warping_function([pitch_scaled_audio], 'quadratic', 0.5)[0]\n",
    "    power_warped_audio = apply_warping_function([pitch_scaled_audio], 'power', -0.5)[0]\n",
    "    piecewise_linear_warped_audio = piecewise_linear_transformation(pitch_scaled_audio, alpha=1.0, breakpoint=0.5)\n",
    "\n",
    "    # Save transformed audio\n",
    "    sf.write(\"pitch_scaled_audio.wav\", pitch_scaled_audio, sampling_rate, format='WAV', subtype='PCM_24')\n",
    "    sf.write(\"bilinear_warped_audio.wav\", bilinear_warped_audio, sampling_rate, format='WAV', subtype='PCM_24')\n",
    "    sf.write(\"quadratic_warped_audio.wav\", quadratic_warped_audio, sampling_rate, format='WAV', subtype='PCM_24')\n",
    "    sf.write(\"power_warped_audio.wav\", power_warped_audio, sampling_rate, format='WAV', subtype='PCM_24')\n",
    "    sf.write(\"piecewise_linear_warped_audio.wav\", piecewise_linear_warped_audio, sampling_rate, format='WAV', subtype='PCM_24')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning_20220719",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
